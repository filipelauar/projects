{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S05A02_1 - BiLSTM e Torchtext.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i1QxWp04tmc",
        "colab_type": "code",
        "outputId": "2e792801-1576-4311-8a23-09a7bac3d476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f760aa9ff90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjxhn0iD4oA7",
        "colab_type": "code",
        "outputId": "84f28cbe-182d-4cff-84fc-611205b5340d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 10,     # Number of epochs.\n",
        "    'lr': 3e-5,           # Learning rate.\n",
        "    'weight_decay': 5e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 6,     # Number of workers on data loader.\n",
        "    'batch_size': 10,     # Mini-batch size.\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cIQzePy20vP",
        "colab_type": "text"
      },
      "source": [
        "# Bidirectional RNN\n",
        "\n",
        "Documentação Pytorch: https://pytorch.org/docs/stable/nn.html#torch.nn.RNN\n",
        "\n",
        "Redes recorrentes bidirecionais, internamente implementam duas camadas recorrentes, cada qual recebendo a informação em uma ordem diferente. O objetivo é acumular conhecimento da sequência em ambas as direções, adquirindo contexto do passado (esquerda para direita) e do futuro (direita para a esquerda).\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=158b3Y_o-7yXsKMe5VdaifhPg0Du4A6dp)\n",
        "\n",
        "Na implementação, o que muda em relação à camada unidirecional é:\n",
        "*  Ao instanciar a camada recorrente, defina o parâmetro **```bidirectional = True```**\n",
        "*  O hidden state tem dimensionalidade **```(num_layers * 2, batch_size, hidden_size)```**\n",
        "*  O output tem dimensionalidade **```(seq_len, batch_size, hidden_size * 2)```**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbwWNFXpwwgI",
        "colab_type": "code",
        "outputId": "16b3e2ec-cccd-4316-c4e7-2c6b2ce9ab2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class BRNN(nn.Module):\n",
        "  \n",
        "  def __init__(self,input_size, hidden_size, num_layers, batch_size):\n",
        "    super(BRNN, self).__init__()\n",
        "    \n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.brnn = nn.RNN(input_size, hidden_size, num_layers, bidirectional=True)\n",
        "    \n",
        "        \n",
        "  def forward(self, X):\n",
        "    \n",
        "    h0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(args['device'])\n",
        "    \n",
        "    output, hn = self.brnn(X, h0)\n",
        "    print(output.size(), hn.size())\n",
        "    return output\n",
        "    \n",
        "\n",
        "hidden_size   = 64\n",
        "num_layers    = 1\n",
        "input_size    = 1 \n",
        "seq_len       = 140\n",
        "\n",
        "net = BRNN(input_size,\n",
        "             hidden_size, num_layers,\n",
        "             args['batch_size']).to(args['device'])\n",
        "\n",
        "# Generate random batch\n",
        "X = torch.randn(seq_len, args['batch_size'], input_size).to(args['device'])\n",
        "output = net(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([140, 10, 128]) torch.Size([2, 10, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bk1LSBj7Uqx",
        "colab_type": "text"
      },
      "source": [
        "# Long Short-Term Memory\n",
        "\n",
        "A unidade recorrente básica produz apenas uma saída, o seu estado interno $h_t$. Este mesmo estado alimenta tanto as camadas subsequentes quanto a conexão recorrente da unidade. Por essa razão, ao realizar o forward em uma camada recorrente, precisamos inicializar o hidden state $h_t$, e alimentar a rede com o par de parâmetros $x_t, h_{t-1}$ a cada timestep.\n",
        "\n",
        "```python\n",
        "# Instanciando a camada\n",
        "self.rnn = nn.RNN(input_size,  hidden_size, num_layers)\n",
        "\n",
        "# Forward\n",
        "h0 = torch.randn(num_layers, batch_size, hidden_size).to(args['device'])\n",
        "output, hn = self.rnn(X, h0)\n",
        "```\n",
        "\n",
        "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=\"650\">\n",
        "\n",
        "A LSTM por outro lado produz duas saídas, o já conhecido hidden state $h_t$, mas também o cell state $c_t$. É graças ao cell state que a LSTM consegue mitigar o problema do vanishing gradient. De forma análoga aos blocos residuais e densos, que introduzem operações mais estáveis para preservar a força do gradiente, o cell state é atualizado através de uma soma.\n",
        "\n",
        "Na prática, isso interfere na forma como fazemos o forward nessa rede, que agora precisa de dois estados iniciais ```(h0, c0)```, junto com a entrada, como apresentado no trecho de código a seguir.\n",
        "\n",
        "```python\n",
        "# Instanciando a camada\n",
        "self.lstm = nn.LSTM(input_size,  hidden_size, num_layers)\n",
        "\n",
        "# Forward\n",
        "h0 = torch.randn(num_layers, batch_size, hidden_size).to(args['device'])\n",
        "c0 = torch.randn(num_layers, batch_size, hidden_size).to(args['device'])\n",
        "\n",
        "output, (hn, cn) = self.lstm(X, (h0, c0))\n",
        "```\n",
        "\n",
        "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" width=\"650\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4V1slAc7lsC",
        "colab_type": "code",
        "outputId": "3bb9a53d-40c2-411b-c12c-b96b3263f751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self,input_size, hidden_size, num_layers, batch_size):\n",
        "    super(BiLSTM, self).__init__()\n",
        "    \n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=True)\n",
        "    \n",
        "        \n",
        "  def forward(self, X):\n",
        "    \n",
        "    h0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(args['device'])\n",
        "    c0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(args['device'])\n",
        "    \n",
        "    output, (hn, cn) = self.bilstm(X, (h0, c0)) \n",
        "    print(output.size(), hn.size(), cn.size())\n",
        "    return output\n",
        "    \n",
        "\n",
        "hidden_size   = 64\n",
        "num_layers    = 1\n",
        "input_size    = 1 \n",
        "seq_len       = 140\n",
        "\n",
        "net = BiLSTM(input_size,\n",
        "             hidden_size, num_layers,\n",
        "             args['batch_size']).to(args['device'])\n",
        "\n",
        "# Generate random batch\n",
        "X = torch.randn(seq_len, args['batch_size'], input_size).to(args['device'])\n",
        "output = net(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([140, 10, 128]) torch.Size([2, 10, 64]) torch.Size([2, 10, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcvx3O1-x-j7",
        "colab_type": "text"
      },
      "source": [
        "# Empacotando Sequências\n",
        "\n",
        "O pacote de funções de rnn, ```nn.utils.rnn```, oferece meios de processar batches contendo sequências de tamanho variável. Isso é realizado através do **padding** da sequência (ex: preenchimento com zeros),  de modo que elas aparentem ter igual comprimento, porém internamente as posições preenchidas não são processadas pela RNN.\n",
        "\n",
        "*  Assuma um batch de frases de comprimento variável, como apresentado a seguir.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/426/1*7qaPfwTbd6RBUWC5QNHxNw.png\" width=\"350\">\n",
        "\n",
        "*  O empacotamento precisa receber os dados em ordem decrescente de comprimento, e internamente são criados \"mini batches\" com o seu batch. Dessa forma, apenas os timesteps que contém informação relevante sobre o dado são apresentadas à rede. Igualmente, somente esses timesteps impactam no backpropagation.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/668/1*WF93EuCOGU834ENSnnofZg.png\" width=\"360\">\n",
        "\n",
        "\n",
        "Para isso basta realizar o padding das suas sequências, **preservando os comprimetos originais** em outra variável. Na prática, o forward recebe mais um parâmetro, aqui chamamos de **```lengths```**, referente ao comprimento de cada amostra dentro do batch **```X```**, ordenado de forma descrescente.\n",
        "\n",
        "Tendo em mãos (1) o batch de sequências preenchidas e ordenadas, e (2) o comprimento original de cada amostra, basta realizar as seguintes operações no forward da rede:\n",
        "\n",
        "```python\n",
        "## Empacote a sequência antes de alimentar a unidade recorrente\n",
        "packed_input = nn.utils.rnn.pack_padded_sequence(X, lengths)\n",
        "\n",
        "## Forward recorrente\n",
        "packed_output, (hn, cn) = self.bilstm(packed_input, (h0, c0) )\n",
        "\n",
        "## Desempacote a sequência para continuar o fluxo na rede.\n",
        "output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9xrpMDRyJt_",
        "colab_type": "code",
        "outputId": "2176bac4-ec8c-42b4-c4f4-630f132d30e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self,input_size, hidden_size, num_layers, batch_size):\n",
        "    super(BiLSTM, self).__init__()\n",
        "    \n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=True)\n",
        "    \n",
        "        \n",
        "  def forward(self, X, lengths):\n",
        "    \n",
        "    h0 = torch.zeros(self.num_layers * 2, X.size(1), self.hidden_size).to(args['device'])\n",
        "    c0 = torch.zeros(self.num_layers * 2, X.size(1), self.hidden_size).to(args['device'])\n",
        "    \n",
        "    ## Empacote a sequência antes de alimentar a unidade recorrente\n",
        "    print('Input size:', X.size())\n",
        "    packed_input = nn.utils.rnn.pack_padded_sequence(X, lengths)\n",
        "    print('Packed size:', packed_input.data.size())\n",
        "    \n",
        "    ## Forward recorrente\n",
        "    packed_output, (hn, cn) = self.bilstm(packed_input, (h0, c0) )\n",
        "    print('Packed output size:', packed_output.data.size())\n",
        "\n",
        "    ## Desempacote a sequência para continuar o fluxo na rede.\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "    print('Unpacked output size:', output.size())\n",
        "    \n",
        "    return output\n",
        "    \n",
        "\n",
        "hidden_size   = 64\n",
        "num_layers    = 1\n",
        "input_size    = 1 \n",
        "seq_len       = 140\n",
        "\n",
        "net = BiLSTM(input_size,\n",
        "             hidden_size, num_layers,\n",
        "             args['batch_size']).to(args['device'])\n",
        "\n",
        "# Generate random batch\n",
        "seq_lens = [24, 21, 12, 11]\n",
        "max_len  = max(seq_lens)\n",
        "\n",
        "batch = [] \n",
        "for s in seq_lens:\n",
        "  X = torch.randn(s, input_size)\n",
        "  X = torch.cat( (X, torch.zeros(max_len - s, input_size)), dim=0 ).to(args['device'])\n",
        "  \n",
        "  batch.append(X)\n",
        "\n",
        "batch = torch.stack(batch).permute((1,0,2))\n",
        "output = net(batch, seq_lens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size: torch.Size([24, 4, 1])\n",
            "Packed size: torch.Size([68, 1])\n",
            "Packed output size: torch.Size([68, 128])\n",
            "Unpacked output size: torch.Size([24, 4, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRapC1fmuv4C",
        "colab_type": "text"
      },
      "source": [
        "# Torchtext\n",
        "\n",
        "Similar ao torchvision, o pacote torchtext facilita o trabalho com texto, oferecendo ferramentas aproveitáveis para outros contextos (séries temporais, dados tabulares etc.).\n",
        "\n",
        "Vamos experimentar com o dado tabular a seguir, referente ao dataset Sentiment140 de análise de sentimentos, disponível em: http://help.sentiment140.com/for-students"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGm46RKFl3j",
        "colab_type": "code",
        "outputId": "586b042a-64de-4acc-9340-91b3da1c2f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/u7jea1hynnubjb3/140_train_small.csv?dl=1\n",
        "!mv '140_train_small.csv?dl=1' 140_train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-31 18:31:55--  https://www.dropbox.com/s/u7jea1hynnubjb3/140_train_small.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/u7jea1hynnubjb3/140_train_small.csv [following]\n",
            "--2019-07-31 18:31:55--  https://www.dropbox.com/s/dl/u7jea1hynnubjb3/140_train_small.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2a4fa5db494a708bd8a9782fba.dl.dropboxusercontent.com/cd/0/get/AlxLOO3FWGbYi1akbIQsqKfH6Cxm8THpxdWCeaX1--KTTC6-nIs7xqlp8SjVT0_3MNSZA1uIYyJZVlA1V2BVW_DwBn_lcqcPcVAEHcET-3MZDc7lVzw8i3dhU1_Dn7wu4ek/file?dl=1# [following]\n",
            "--2019-07-31 18:31:56--  https://uc2a4fa5db494a708bd8a9782fba.dl.dropboxusercontent.com/cd/0/get/AlxLOO3FWGbYi1akbIQsqKfH6Cxm8THpxdWCeaX1--KTTC6-nIs7xqlp8SjVT0_3MNSZA1uIYyJZVlA1V2BVW_DwBn_lcqcPcVAEHcET-3MZDc7lVzw8i3dhU1_Dn7wu4ek/file?dl=1\n",
            "Resolving uc2a4fa5db494a708bd8a9782fba.dl.dropboxusercontent.com (uc2a4fa5db494a708bd8a9782fba.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc2a4fa5db494a708bd8a9782fba.dl.dropboxusercontent.com (uc2a4fa5db494a708bd8a9782fba.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14796848 (14M) [application/binary]\n",
            "Saving to: ‘140_train_small.csv?dl=1’\n",
            "\n",
            "140_train_small.csv 100%[===================>]  14.11M  35.8MB/s    in 0.4s    \n",
            "\n",
            "2019-07-31 18:31:57 (35.8 MB/s) - ‘140_train_small.csv?dl=1’ saved [14796848/14796848]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8YAZHL2yN6n",
        "colab_type": "text"
      },
      "source": [
        "## TabularDataset\n",
        "\n",
        "Essa classe permite a construção de datasets acessando diretamente a tabela onde os dados estão contidos.\n",
        "É possível filtrar as colunas que irão compor o dataset e ignorar o restante da informação através de ```Fields```, que nada mais são do que tipos de dados que incorporam instruções de transformações.\n",
        "\n",
        "Documentação: https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.TabularDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFWam8fCSZBi",
        "colab_type": "code",
        "outputId": "aa0a435f-6e66-4bac-e976-0eddd9ccbc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('140_train.csv')\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>106661</th>\n",
              "      <td>4</td>\n",
              "      <td>2193576427</td>\n",
              "      <td>Tue Jun 16 08:38:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>wonder_nat</td>\n",
              "      <td>@AndrewDearling *yawns*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106662</th>\n",
              "      <td>4</td>\n",
              "      <td>2193577154</td>\n",
              "      <td>Tue Jun 16 08:38:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>kcnitt</td>\n",
              "      <td>oh yes, and btw, 8.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106663</th>\n",
              "      <td>4</td>\n",
              "      <td>2193577726</td>\n",
              "      <td>Tue Jun 16 08:38:52 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>FrayBaby</td>\n",
              "      <td>@pokapolas love the donut and the toadstool.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106664</th>\n",
              "      <td>4</td>\n",
              "      <td>2193578347</td>\n",
              "      <td>Tue Jun 16 08:38:55 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>CoachChic</td>\n",
              "      <td>@BizCoachDeb  Hey, I'm baack! And, thanks so m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106665</th>\n",
              "      <td>4</td>\n",
              "      <td>2193579249</td>\n",
              "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>razzberry5594</td>\n",
              "      <td>WOOOOO! Xbox is back</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
              "106661  4  ...                           @AndrewDearling *yawns*                                                                   \n",
              "106662  4  ...                             oh yes, and btw, 8.00                                                                   \n",
              "106663  4  ...     @pokapolas love the donut and the toadstool.                                                                    \n",
              "106664  4  ...  @BizCoachDeb  Hey, I'm baack! And, thanks so m...                                                                  \n",
              "106665  4  ...                              WOOOOO! Xbox is back                                                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f881b2c1-4829-4570-f0b4-7f8748fb8c68",
        "id": "9WPQXd0dSSuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tokenize = lambda x: x.split()\n",
        "\n",
        "TEXT = data.Field(tokenize=tokenize, include_lengths=True)\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "fields = [('label', LABEL), (None, None), (None, None), (None, None), (None, None), ('text', TEXT)]\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "                                  path = '.',\n",
        "                                  train = '140_train.csv',\n",
        "                                  test = '140_train.csv',\n",
        "                                  format = 'csv',\n",
        "                                  fields = fields,\n",
        "                                  skip_header = False)\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "\n",
        "for sample in train_data:\n",
        "  print(sample.text)\n",
        "  print(sample.label)\n",
        "  break\n",
        "  \n",
        "print(len(train_data), len(valid_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@TheScottyDont', 'Awwww,', \"you're\", 'so', 'nice']\n",
            "4\n",
            "74667 32000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfvAnIg3Eqom",
        "colab_type": "text"
      },
      "source": [
        "## Vocabulary\n",
        "\n",
        "Uma pergunta que pode ter passado na sua cabeça: como alimentamos uma rede neural com palavras de um texto?\n",
        "\n",
        "Para transformar palavras em dados numéricos, a solução mais simples é mapeá-las em um dicionário contendo o vocabulário completo do conjunto. \n",
        "\n",
        "<img src=\"https://static.packt-cdn.com/products/9781786465825/graphics/B05525_03_01.jpg\" width=\"500\">\n",
        "\n",
        "Podemos fazer isso chamando a função **```build_vocab```** nos nossos fields. Como datasets de texto podem chegar a centenas de milhares de palavras, é importante definir um limite superior para o número de palavras mapeadas pelo dicionário. No código a seguir, esse limite é definido como ```MAX_VOCAB_SIZE = 25000```\n",
        "\n",
        "Atenção também para o parâmetro ```vectors = \"glove.6B.100d\"```. O GloVe (Global Vectors) é um método de representação de palavras que explicaremos em maiores detalhes mais a frente. A princípio basta saber que o modelo \"glove.**6B**.**100d**\" foi treinado em **6 bilhões** de palavras e gera uma representação latente de dimensionalidade  **d = 100**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtLYbJe-Cews",
        "colab_type": "code",
        "outputId": "b71e655f-d3c8-4f61-cac7-fc853f8e81a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "# Vocabulário com 25000 + <PAD> + <UNK>\n",
        "len(TEXT.vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [00:44, 19.2MB/s]                           \n",
            "100%|█████████▉| 398734/400000 [00:22<00:00, 17162.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzYXHWDQwOCh",
        "colab_type": "text"
      },
      "source": [
        "## BucketIterator\n",
        "Essa classe funciona de forma análoga ao DataLoader que conhecemos,  porém leva em consideração a construção de batches contendo sequências de comprimento variável. Internamente ele agrega sequências de comprimento similar, minimizando a quantidade de padding necessária. Além disso, os dados já saem preparados para serem empacotados pela função ```pack_padded_sequence``` ordenados por comprimento de sequência e informando o comprimento real de cada amostra (sem padding).\n",
        "\n",
        "Documentação: https://torchtext.readthedocs.io/en/latest/data.html?highlight=BucketIterator#torchtext.data.BucketIterator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPWuKY7w4wrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = args['batch_size'],\n",
        "    sort_key = lambda x:len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    device = args['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbPhKgFfwQhi",
        "colab_type": "code",
        "outputId": "4583e7b9-e368-43a1-e55b-74ccbdea0414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "for batch in train_iterator:\n",
        "  text, lengths = batch.text\n",
        "  print(text)\n",
        "  print(lengths)\n",
        "  print(batch.label)\n",
        "  \n",
        "  print([TEXT.vocab.itos[t] for t in text[0]])\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3837,     0,   255,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   22,  2161,     4,  9409,     8, 14343, 18952,   115, 23598,  6540],\n",
            "        [  954,  1350,   817,    10,   158,     8,     0,    51,     4,    80],\n",
            "        [   33,     7,    10,    67,   161,  6649,  1622,    55,    73,     0],\n",
            "        [    9,    38,    40,     8,    50,  5337,   434, 11343,     0,    90],\n",
            "        [   82,   402,    15,    57,  4386, 12675,     9,  6466, 10096,     2],\n",
            "        [   10,    20, 10752,   631,   833,  6613,  3899,   178,     0,    50],\n",
            "        [ 2459,  8950,     0,     1,     1,     1,     1,     1,     1,     1]],\n",
            "       device='cuda:0')\n",
            "tensor([8, 8, 8, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
            "tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0')\n",
            "['@johncmayer', '<unk>', 'What', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2Qv2s1YFNli",
        "colab_type": "text"
      },
      "source": [
        "# Embedding Layer\n",
        "\n",
        "Documentação Pytorch: https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding\n",
        "\n",
        "Camadas de embedding são treinadas para mapear um ínidice numérico para um vetor denso de maior carga semântica.\n",
        "\n",
        "Acabamos de ver a representação de palaras como ínidices de um vocabulário fixo. Apesar do índice informar a qual palavra estamos nos referindo, ele não incorpora nenhuma informação semântica sobre a palavra. O treinamento de embeddings para dados textuais tem como objetivo projetar esses índices em um espaço onde palavras semanticamente similares estejam próximas.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1pliMSOcjjOZAiR26ycowSeUJsj5cy9W_)\n",
        "\n",
        "No Pytorch, a instância dessa classe recebe como parâmetro ```(vocab_size, embedding_size, padding_idx)```\n",
        "* ```vocab_size```: Tamanho do vocabulário. Note que **não** se trata da dimensionalidade da entrada.\n",
        "* ```embedding_size```: Dimensionalidade da dimensão latente. Caso haja o aproveitamento de embeddings pré treinadas deve-se definir a dimensionalidade da camada em função dos pesos que serão importados (ex: glove.6b.100d, ```embedding_size=100```).\n",
        "* ```padding_idx```: Parâmetro **opcional** que retorna um tensor de zeros quando recebe instâncias com esse índice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzv1cygUOdZC",
        "colab_type": "code",
        "outputId": "8d5d8503-0143-4f2d-ff65-530a672038b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "class BRNN(nn.Module):\n",
        "  \n",
        "  def __init__(self,vocab_size, embedding_size, hidden_size, num_layers, batch_size,\n",
        "              embedding_weights=None, pad_idx=None, unk_idx=None):\n",
        "    super(BRNN, self).__init__()\n",
        "    \n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_idx)\n",
        "    self.brnn  = nn.RNN(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
        "    \n",
        "    if embedding_weights is not None:\n",
        "        self.init_embedding(embedding_weights, pad_idx, unk_idx, embedding_size)\n",
        "        \n",
        "  def init_embedding(self, weights, pad_idx, unk_idx, embedding_size):\n",
        "    \n",
        "    self.embed.weight.data.copy_(weights)\n",
        "    self.embed.weight.data[unk_idx] = torch.zeros(embedding_size)\n",
        "    self.embed.weight.data[pad_idx] = torch.zeros(embedding_size)\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    pass\n",
        "    \n",
        "\n",
        "hidden_size    = 64\n",
        "num_layers     = 1\n",
        "embedding_size = 100\n",
        "vocab_size     = len(TEXT.vocab)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "net = BRNN(vocab_size, embedding_size,\n",
        "           hidden_size, num_layers,\n",
        "           args['batch_size'],\n",
        "           pretrained_embeddings, PAD_IDX,\n",
        "           UNK_IDX).to(args['device'])\n",
        "\n",
        "# Batch do Sentiment140\n",
        "for batch in train_iterator:\n",
        "  text, lengths = batch.text\n",
        "  \n",
        "  sample = text[:,0]\n",
        "  \n",
        "  print(\"Sequence length:\", len(sample) )\n",
        "  print(\"Vocabulary indices for each word:\", sample)\n",
        "  \n",
        "  embedding = net.embed(sample)\n",
        "  print(\"\\n\\nEmbedding output size:\", embedding.size())\n",
        "  print(\"Embedding vectors:\", embedding)\n",
        "  \n",
        "  break\n",
        "  \n",
        "\n",
        "X = torch.randn(seq_len, args['batch_size'], input_size).to(args['device'])\n",
        "output = net(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence length: 27\n",
            "Vocabulary indices for each word: tensor([ 5036,    96,   759,   468,     0,  3967,    27,    16,     0,    22,\n",
            "           96,   168,    89,     0,     0, 24948,    96, 10568, 16894, 19965,\n",
            "         2109,  4681,   137,    89,   339, 16416,  4238], device='cuda:0')\n",
            "\n",
            "\n",
            "Embedding output size: torch.Size([27, 100])\n",
            "Embedding vectors: tensor([[ 1.1866e+00, -5.6253e-01,  1.1038e+00,  ..., -3.4591e-01,\n",
            "         -8.2398e-02,  2.3621e+00],\n",
            "        [-1.7358e-01, -3.6788e-01, -2.9992e-01,  ..., -2.5977e-01,\n",
            "          6.5464e-01,  4.6558e-01],\n",
            "        [ 1.7581e+00,  2.2177e+00,  7.7441e-01,  ..., -2.3919e-01,\n",
            "         -1.1639e+00,  5.1103e-01],\n",
            "        ...,\n",
            "        [-9.6620e-01, -3.3769e-01,  1.6463e-01,  ...,  4.0199e-01,\n",
            "         -1.1374e+00,  1.9768e+00],\n",
            "        [-2.4989e-01,  5.6004e-02,  1.2962e+00,  ..., -4.7342e-01,\n",
            "         -2.1616e-01,  1.1519e-03],\n",
            "        [ 5.7099e-01,  3.6458e-02,  1.0264e+00,  ...,  4.2581e-01,\n",
            "          4.0433e-01,  3.3241e-01]], device='cuda:0',\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}