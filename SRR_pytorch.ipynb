{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSR pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7ea3cedf3e24acdaada044c93efe4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd7fabff3de6418aa1695677802361fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56148c92efee49979a1c25a2e861e9de",
              "IPY_MODEL_f3129bb0dddf4a5f865992acf9241894",
              "IPY_MODEL_ba95eee1d353495cbca1aa537aa4396a"
            ]
          }
        },
        "bd7fabff3de6418aa1695677802361fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56148c92efee49979a1c25a2e861e9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b5bddf28fb14e0ba19e0b6586e806b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d791f83bb2f49dd90e94bfdf9f1f8d3"
          }
        },
        "f3129bb0dddf4a5f865992acf9241894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0058275151b47e6a6399a003d96dc1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44935b691ff747e88939c81349b61f2d"
          }
        },
        "ba95eee1d353495cbca1aa537aa4396a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4bc859cbd9d74d989d44e80c497fd516",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:05&lt;00:00, 43576256.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1696ecfd150f4da89c00048fdf1316bf"
          }
        },
        "6b5bddf28fb14e0ba19e0b6586e806b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d791f83bb2f49dd90e94bfdf9f1f8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0058275151b47e6a6399a003d96dc1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44935b691ff747e88939c81349b61f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bc859cbd9d74d989d44e80c497fd516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1696ecfd150f4da89c00048fdf1316bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***This is the implementation of the [Self-supervise, refine, repeat: improving unsupervised anomaly detection](https://openreview.net/pdf?id=Nct9j3BVswZ)\n",
        " paper in Pytorch.***\n",
        "\n",
        " In this notebook you will find the implementation of SSR for both contrastive and rotation losses and using as One Class Classifier OneClassSVM and also Gaussian Mixture + mahalanobis distance. You can apply it in 3 different datasets.\n"
      ],
      "metadata": {
        "id": "cMahkn-FIkYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78WCBs5_9Hj0",
        "outputId": "f944ddaa-6173-468c-d4be-f014f96ef1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import  SubsetRandomSampler \n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre processing function and dataset classes"
      ],
      "metadata": {
        "id": "F3YB68_0SyUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pre processing and dataset class\n",
        "\n",
        "#pre processing and dataset class\n",
        "def preprocess_dataset(data, label, nclasses, normal_class=0, abnormal_rate=0.1):\n",
        "  out = []\n",
        "  toPil = transforms.ToPILImage()\n",
        "  for x, y in zip(data, label):\n",
        "    if dataset == 'fmnist':\n",
        "        x = toPil(x.repeat(3,1,1))\n",
        "    elif dataset == 'cifar10':\n",
        "        x = toPil(x)\n",
        "    if y == normal_class:\n",
        "      out.append((x, 0))\n",
        "    else:\n",
        "      if np.random.rand(1) < abnormal_rate/(nclasses-1):\n",
        "        out.append((x, 1))\n",
        "\n",
        "  return out\n",
        "\n",
        "  class ContrastiveDataset(Dataset):\n",
        "    def __init__(self, data, transform=None, contrastive = False):\n",
        "        self.data = data   \n",
        "        self.transform = transform\n",
        "        self.contrastive = contrastive\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx]\n",
        "        \n",
        "        if self.contrastive:\n",
        "          img1 = self.transform(img)\n",
        "          img2 = self.transform(img)\n",
        "          return img1, img2\n",
        "\n",
        "        return self.transform(img), label\n",
        "\n",
        "class RotationDataset(Dataset):\n",
        "    def __init__(self, data, rotate = False, transform=None):\n",
        "        self.data = data   \n",
        "        self.transform = transform\n",
        "        self.rotate = rotate\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx]\n",
        "        \n",
        "        if self.rotate:\n",
        "          label = np.random.randint(4)\n",
        "          img = torch.rot90(img, label)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "34if-xR2ZbCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive\n",
        "\n",
        "Two different implementations of contrastive loss. "
      ],
      "metadata": {
        "id": "QSs6sOKuSA1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#contrastive loss implementation modified from https://github.com/HobbitLong/SupContrast/blob/master/losses.py and https://medium.com/the-owl/simclr-in-pytorch-5f290cb11dd7\n",
        "\n",
        "\n",
        "\n",
        "class SupConLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
        "                 base_temperature=0.07):\n",
        "        super(SupConLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.contrast_mode = contrast_mode\n",
        "        self.base_temperature = base_temperature\n",
        "\n",
        "    def forward(self, features):\n",
        "        device = (torch.device('cuda')\n",
        "                  if features.is_cuda\n",
        "                  else torch.device('cpu'))\n",
        "\n",
        "        batch_size = features.shape[0]\n",
        "        mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
        "\n",
        "        contrast_count = 2\n",
        "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
        "        if self.contrast_mode == 'one':\n",
        "            anchor_feature = features[:, 0]\n",
        "            anchor_count = 1\n",
        "        elif self.contrast_mode == 'all':\n",
        "            anchor_feature = contrast_feature\n",
        "            anchor_count = contrast_count\n",
        "        else:\n",
        "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
        "\n",
        "        # compute logits\n",
        "        anchor_dot_contrast = torch.div(\n",
        "            torch.matmul(anchor_feature, contrast_feature.T),\n",
        "            self.temperature)\n",
        "        # for numerical stability\n",
        "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
        "        logits = anchor_dot_contrast - logits_max.detach()\n",
        "\n",
        "        # tile mask\n",
        "        mask = mask.repeat(anchor_count, contrast_count)\n",
        "        # mask-out self-contrast cases\n",
        "        logits_mask = torch.scatter(\n",
        "            torch.ones_like(mask),\n",
        "            1,\n",
        "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
        "            0\n",
        "        )\n",
        "        mask = mask * logits_mask\n",
        "\n",
        "        # compute log_prob\n",
        "        exp_logits = torch.exp(logits) * logits_mask\n",
        "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
        "\n",
        "        # compute mean of log-likelihood over positive\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
        "\n",
        "        # loss\n",
        "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
        "        loss = loss.view(anchor_count, batch_size).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class NT_Xent(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super(NT_Xent, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
        "\n",
        "    def mask_correlated_samples(self, batch_size):\n",
        "        N = 2 * batch_size\n",
        "        mask = torch.ones((N, N), dtype=bool)\n",
        "        mask = mask.fill_diagonal_(0)\n",
        "        for i in range(batch_size):\n",
        "            mask[i, batch_size + i] = 0\n",
        "            mask[batch_size + i, i] = 0\n",
        "        return mask\n",
        "\n",
        "    def forward(self, features):\n",
        "        \"\"\"\n",
        "        We do not sample negative examples explicitly.\n",
        "        Instead, given a positive pair, similar to (Chen et al., 2017), we treat the other 2(N − 1) augmented examples within a minibatch as negative examples.\n",
        "        \"\"\"\n",
        "        batch_size = features.shape[0]\n",
        "        N = 2 * batch_size\n",
        "\n",
        "        z = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
        "        mask = self.mask_correlated_samples(batch_size)\n",
        "\n",
        "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
        "\n",
        "        sim_i_j = torch.diag(sim, batch_size)\n",
        "        sim_j_i = torch.diag(sim, -batch_size)\n",
        "\n",
        "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
        "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
        "        negative_samples = sim[mask].reshape(N, -1)\n",
        "\n",
        "        labels = torch.zeros(N).to(positive_samples.device).long()\n",
        "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        loss /= N\n",
        "        return loss"
      ],
      "metadata": {
        "id": "B6dQIDRnQH_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contrastive model"
      ],
      "metadata": {
        "id": "8ARvTS6vSJFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PreModel(nn.Module):\n",
        "    def __init__(self, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        \n",
        "        #PRETRAINED MODEL\n",
        "        self.pretrained = resnet18(pretrained=False, num_classes=4 * hidden_dim)\n",
        "        \n",
        "        self.projectionHead = nn.Sequential(\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4 * hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        \n",
        "        out = self.pretrained(x)\n",
        "        out = self.projectionHead(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "avWtcqEjzWyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCC score"
      ],
      "metadata": {
        "id": "aQYdyw-fSPDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_samples(data, occ):\n",
        "    '''OCC has to be 1-component gaussian model'''\n",
        "    #calculate Mahalanobis distance\n",
        "    mahalanobis = []\n",
        "    mu = occ.means_\n",
        "    sigmainv = np.linalg.inv(occ.covariances_)\n",
        "\n",
        "    for d in data:\n",
        "      res = np.dot((d-mu), np.dot(sigmainv, (d-mu).T))\n",
        "      mahalanobis.append(res)\n",
        "\n",
        "    return np.asarray(mahalanobis)"
      ],
      "metadata": {
        "id": "1RwNG5NhSR6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and feature extraction functions\n",
        "\n",
        "Training function for both rotation and contrastive"
      ],
      "metadata": {
        "id": "4c01asBDSUXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training functions\n",
        "    \n",
        "\n",
        "def train(model, data, criterion, optimizer, epoch):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),])\n",
        "  \n",
        "    data = RotationDataset(data, transform=transform)\n",
        "\n",
        "    batch_size = 100\n",
        "    train_loader = DataLoader(data, batch_size, drop_last=True)\n",
        "\n",
        "    l, i=0, 0\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x = x.float().to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(x)\n",
        "        loss = criterion(yhat, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        l+=loss.item()\n",
        "\n",
        "    del data\n",
        "    del train_loader\n",
        "        \n",
        "    print(\"Epoch:\", epoch+1, \"self-supervised rotation loss:\", l/i)\n",
        "    return l/i\n",
        "\n",
        "def extract_features(data, model):\n",
        "  transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),])\n",
        "  \n",
        "  data = RotationDataset(data, transform=transform)\n",
        "  \n",
        "  batch_size = 100\n",
        "  train_loader = DataLoader(data, batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "  model.eval()\n",
        "  out = []\n",
        "  for inps, labs in train_loader:\n",
        "      inps, labs = inps.float().to(device), labs.to(device)\n",
        "      features = model.feature_extractor(inps).squeeze(2).squeeze(2)\n",
        "      out.append(features)\n",
        "\n",
        "  del data\n",
        "  del train_loader\n",
        "  \n",
        "  #return the extracted features\n",
        "  return torch.cat(out,dim=0).cpu().detach().numpy()\n",
        "  \n",
        "class ContrastiveDataset(Dataset):\n",
        "    def __init__(self, data, transform=None, contrastive = False):\n",
        "        self.data = data   \n",
        "        self.transform = transform\n",
        "        self.contrastive = contrastive\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx]\n",
        "        \n",
        "        if self.contrastive:\n",
        "          img1 = self.transform(img)\n",
        "          img2 = self.transform(img)\n",
        "          return img1, img2\n",
        "\n",
        "        return self.transform(img), label\n",
        "\n",
        "class RotationDataset(Dataset):\n",
        "    def __init__(self, data, rotate = False, transform=None):\n",
        "        self.data = data   \n",
        "        self.transform = transform\n",
        "        self.rotate = rotate\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx]\n",
        "        \n",
        "        if self.rotate:\n",
        "          label = np.random.randint(4)\n",
        "          img = torch.rot90(img, label)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "def train_contrastive(model, data, criterion, optimizer, epoch):\n",
        "    contrast_transforms = transforms.Compose(\n",
        "      [\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomResizedCrop(size=28),\n",
        "          transforms.RandomApply([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
        "          transforms.RandomGrayscale(p=0.2),\n",
        "          transforms.GaussianBlur(kernel_size=9),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,), (0.5,)),\n",
        "      ]\n",
        "  )\n",
        "    \n",
        "    batch_size = 100\n",
        "    data = ContrastiveDataset(data, transform=contrast_transforms, contrastive=True)\n",
        "    \n",
        "    train_loader = DataLoader(data, batch_size, drop_last=True)\n",
        "\n",
        "    l, i=0, 0\n",
        "    model.train()\n",
        "    for i, (x1, x2) in enumerate(train_loader):\n",
        "        x1 = x1.float().to(device)\n",
        "        x2 = x2.float().to(device)\n",
        "        \n",
        "        y1 = model(x1).unsqueeze(1)\n",
        "        y2 = model(x1).unsqueeze(1)\n",
        "\n",
        "        y = torch.cat([y1,y2], dim=1)\n",
        "\n",
        "        loss = criterion(y)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        l+=loss.item()\n",
        "\n",
        "    del data\n",
        "    del train_loader\n",
        "    \n",
        "    print(\"Epoch:\", epoch+1, \"self-supervised contrastive loss:\", l/i)\n",
        "    return l/i\n",
        "\n",
        "def extract_features_contrastive(data, model):\n",
        "  transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),])\n",
        "  \n",
        "  batch_size = 100\n",
        "\n",
        "  data = ContrastiveDataset(data, transform=transform, contrastive=False)\n",
        "\n",
        "  \n",
        "  train_loader = DataLoader(data, batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "  model.eval()\n",
        "  out = []\n",
        "  for inps, labs in train_loader:\n",
        "      inps, labs = inps.float().to(device), labs.to(device)\n",
        "      features = model(inps).squeeze(1)\n",
        "      out.append(features)\n",
        "\n",
        "  del data\n",
        "  del train_loader\n",
        "  \n",
        "  #return the extracted features\n",
        "  return torch.cat(out,dim=0).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "io95XfvaSbhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SSR algorithm\n",
        "\n",
        "Implementation from the paper using Gaussian Mixture model as OCC"
      ],
      "metadata": {
        "id": "ythTibGESl7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SSR algorithm\n",
        "\n",
        "def refine_data(data, model, k, th, occ_type):\n",
        "    if ss_type == 'rotation':\n",
        "      data = extract_features(data, model)\n",
        "    else:\n",
        "      data = extract_features_contrastive(data, model)\n",
        "\n",
        "    models = []\n",
        "\n",
        "    #divide k sets\n",
        "    total_idx = list(range(len(data)))\n",
        "    np.random.shuffle(total_idx)\n",
        "    indices = np.array_split(total_idx, k)\n",
        "    nu = []\n",
        "    #split the data\n",
        "    for idx in indices:\n",
        "        data_hat = data[idx]\n",
        "        #train OCC for disjoint set k\n",
        "        if occ_type == 'svm':\n",
        "          occ = OneClassSVM(kernel='rbf', gamma=.01)\n",
        "        else:\n",
        "          occ = GaussianMixture(n_components=1, covariance_type=\"tied\", reg_covar=1e-02)\n",
        "        occ.fit(data_hat)\n",
        "        #append the nu and the model\n",
        "        if occ_type == 'svm':\n",
        "          nu.append(np.quantile(-occ.score_samples(data_hat), th))\n",
        "        else:\n",
        "          nu.append(np.quantile(score_samples(data_hat, occ), th))\n",
        "        models.append(occ)\n",
        "    \n",
        "    #actual threhshold nu is the maximum threhshold found\n",
        "    nk = max(nu)\n",
        "\n",
        "    y = np.zeros(len(data))\n",
        "    for occ_act in models:\n",
        "        #predict the score samples for each data point for each model\n",
        "        if occ_type == 'svm':\n",
        "          res = -occ.score_samples(data)\n",
        "        else:\n",
        "          res = score_samples(data, occ_act).squeeze(1).squeeze(1)\n",
        "        res2 = res >= nk\n",
        "        y += res2\n",
        "\n",
        "    #if all models predicted as normal, it's a normal data point\n",
        "    normal_idx = np.where(y == 0)[0]\n",
        "    \n",
        "    #return only the index of normal data to update the feature extractor\n",
        "    return normal_idx\n",
        "\n",
        "def SSR(data, k, th, model, nepochs=300, early_stopping=80, verbose=10, occ_type='svm'):\n",
        "  \n",
        "    best_loss = 100000\n",
        "    es = 0\n",
        "\n",
        "    for epoch in range(nepochs):\n",
        "        #refined data, a.k.a. normal data points\n",
        "        refined_data_idx = refine_data(data, model, k, th, occ_type)\n",
        "        #just a trick to iterate over a tuple, can't just do data[refined_data_idx]\n",
        "        data_to_train = [data[index] for index in refined_data_idx]\n",
        "        #train the feature extractor\n",
        "        print('--------------------------------------------------------------------')\n",
        "        \n",
        "        if ss_type == 'rotation':\n",
        "          act_loss = train(model, data_to_train, criterion, optimizer, epoch)\n",
        "        else:\n",
        "          act_loss = train_contrastive(model, data_to_train, criterion, optimizer, epoch)\n",
        "\n",
        "        es+=1\n",
        "        #update best model weights\n",
        "        if act_loss < best_loss:\n",
        "          best_loss = act_loss\n",
        "          es=0\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        if verbose!= 0 and epoch%verbose == 0:\n",
        "          occ = GaussianMixture(n_components=1, covariance_type=\"tied\", reg_covar=1e-02)\n",
        "          if ss_type == 'rotation':\n",
        "            data_to_train = extract_features(data_to_train, model)\n",
        "          else:\n",
        "            data_to_train = extract_features_contrastive(data_to_train, model)\n",
        "          occ.fit(data_to_train)\n",
        "\n",
        "          #Evaluate on train set\n",
        "          print('Train evaluation')\n",
        "          evaluate(model, occ, data)\n",
        "          print('Test evaluation')\n",
        "          evaluate(model, occ, testset_tuple)\n",
        "\n",
        "        # Early stopping condition\n",
        "        if es >= early_stopping:\n",
        "            break\n",
        "\n",
        "        del data_to_train\n",
        "    \n",
        "    #load the weights of the best epoch\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    #train the final OCC with the refined data\n",
        "    if occ_type=='svm':\n",
        "      occ = OneClassSVM(kernel='rbf', gamma=.01)\n",
        "    else:\n",
        "      occ = GaussianMixture(n_components=1, covariance_type=\"tied\", reg_covar=1e-02)\n",
        "      \n",
        "    refined_data_idx = refine_data(data, model, k, th, occ_type)\n",
        "    data_to_extract = [data[index] for index in refined_data_idx]\n",
        "\n",
        "    if ss_type == 'rotation':\n",
        "      refined_data = extract_features(data_to_extract, model)\n",
        "    else:\n",
        "      refined_data = extract_features_contrastive(data_to_extract, model)\n",
        "\n",
        "    occ.fit(refined_data)\n",
        "    \n",
        "    return refined_data_idx, occ, model"
      ],
      "metadata": {
        "id": "3vqlgIkd9c-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation functions"
      ],
      "metadata": {
        "id": "xfX6lbVySvGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation metrics\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "def anomaly_ratio_prediction(pred, data):\n",
        "  nAnomalies = sum(pred)\n",
        "  sNormals, sAnormals = 0, 0\n",
        "  for i in range(len(pred)):\n",
        "      if pred[i] == 1:\n",
        "        if data[i][1] == 0:\n",
        "          sNormals+=1\n",
        "        else:\n",
        "          sAnormals+=1\n",
        "\n",
        "  removedNormalSamples, removedAnormalSamples = sNormals/nAnomalies, sAnormals/nAnomalies\n",
        "\n",
        "  return removedNormalSamples, removedAnormalSamples\n",
        "\n",
        "def average_precision(pred, data):\n",
        "  y = []\n",
        "  for i in range(len(pred)):\n",
        "      y.append(data[i][1])\n",
        "\n",
        "  return metrics.average_precision_score(y, pred)\n",
        "\n",
        "def f1(pred, data):\n",
        "  y = []\n",
        "  for i in range(len(pred)):\n",
        "      y.append(data[i][1])\n",
        "\n",
        "  return metrics.f1_score(y, pred)\n",
        "\n",
        "def auc(pred, data):\n",
        "  y = []\n",
        "  for i in range(len(pred)):\n",
        "      y.append(data[i][1])\n",
        "\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
        "\n",
        "  return metrics.auc(fpr, tpr)\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model, occ, data):\n",
        "  if ss_type == 'rotation':\n",
        "    extracted_data = extract_features(data, model)\n",
        "  else:\n",
        "    extracted_data = extract_features_contrastive(data, model)\n",
        "  score = score_samples(extracted_data, occ).squeeze(1).squeeze(1)\n",
        "  \n",
        "  final_th = np.quantile(score, th)\n",
        "  pred = [int(preds) for preds in score > final_th]\n",
        "  \n",
        "  print(\"F1: {:.2f}  AUC: {:.2f}  Average precision: {:.2f}\".format(f1(pred, data), auc(pred, data), average_precision(pred, data)))\n"
      ],
      "metadata": {
        "id": "_K8ZgGc4GRM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST, Cifar10 and cat vs dog"
      ],
      "metadata": {
        "id": "Sjk1pTzUBV1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define dataset and model\n",
        "\n",
        "dataset = 'cifar10'\n",
        "ss_type='contrastive'"
      ],
      "metadata": {
        "id": "C_pyacWja0oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download cat vs dog dataset\n",
        "if dataset=='catdog':\n",
        "  !wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
        "\n",
        "  # remove existing directories\n",
        "  !rm -r Cat_Dog_data __MACOSX || true\n",
        "  !unzip -qq Cat_Dog_data.zip"
      ],
      "metadata": {
        "id": "hIT8BiN9aIyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load datasets\n",
        "transform = transforms.Compose([]) \n",
        "\n",
        "if dataset == 'catdog':\n",
        "  catDog_transforms = transforms.Compose([transforms.Resize((224,224)),])\n",
        "  trainset = datasets.ImageFolder('Cat_Dog_data/train', transform=catDog_transforms)\n",
        "  trainset.data = [trainset[i][0] for i in np.random.randint(0, len(trainset), 5000)] #taking only a small subset of data\n",
        "elif dataset == 'fmnist':\n",
        "  trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True)\n",
        "else:\n",
        "  trainset = datasets.CIFAR10(root='data/', download=True, transform=transform)\n",
        "\n",
        "#pre process dataset\n",
        "abnormal_rate=0.02\n",
        "trainset_tuple = preprocess_dataset(trainset.data, trainset.targets, len(trainset.classes), abnormal_rate=abnormal_rate)\n",
        "\n",
        "#Test set\n",
        "\n",
        "if dataset == 'catdog':\n",
        "  testset = datasets.ImageFolder('Cat_Dog_data/test', transform=catDog_transforms)\n",
        "elif dataset == 'fmnist':\n",
        "  testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True, transform=transform)\n",
        "else:\n",
        "  testset = datasets.CIFAR10(root='data/', download=True, transform=transform)\n",
        "\n",
        "testset_tuple = preprocess_dataset(testset.data, testset.targets, len(testset.classes), abnormal_rate=abnormal_rate)\n",
        "\n",
        "#del trainset\n",
        "#del testset"
      ],
      "metadata": {
        "id": "rnq41LcDBT3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "d7ea3cedf3e24acdaada044c93efe4aa",
            "bd7fabff3de6418aa1695677802361fc",
            "56148c92efee49979a1c25a2e861e9de",
            "f3129bb0dddf4a5f865992acf9241894",
            "ba95eee1d353495cbca1aa537aa4396a",
            "6b5bddf28fb14e0ba19e0b6586e806b1",
            "5d791f83bb2f49dd90e94bfdf9f1f8d3",
            "a0058275151b47e6a6399a003d96dc1e",
            "44935b691ff747e88939c81349b61f2d",
            "4bc859cbd9d74d989d44e80c497fd516",
            "1696ecfd150f4da89c00048fdf1316bf"
          ]
        },
        "outputId": "3d5dd3f0-ae65-4f04-edd5-fcf03c319ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7ea3cedf3e24acdaada044c93efe4aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparision between SRR and without SRR."
      ],
      "metadata": {
        "id": "6ybWYRcba_bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot graphs\n",
        "\n",
        "auc_score = []\n",
        "auc_score_srr = []\n",
        "\n",
        "abn_rates = [0.02,  0.1]\n",
        "seeds = [1,2]\n",
        "\n",
        "occ_type='svm'\n",
        "ss_type='contrastive'\n",
        "\n",
        "for abnormal_rate in abn_rates:\n",
        "  auc_score_seed = []\n",
        "  auc_score_srr_seed = [] \n",
        "  trainset_tuple = preprocess_dataset(trainset.data, trainset.targets, len(trainset.classes), abnormal_rate=abnormal_rate)\n",
        "  testset_tuple = preprocess_dataset(testset.data, testset.targets, len(testset.classes), abnormal_rate=abnormal_rate)\n",
        "\n",
        "  for seed in seeds:\n",
        "    torch.manual_seed(seed)\n",
        "    #SRR\n",
        "    if ss_type == 'rotation':\n",
        "      rotations_number = 4\n",
        "      model = resnet18(pretrained=False, num_classes=rotations_number).to(device)\n",
        "      feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "      model.feature_extractor = feature_extractor\n",
        "      criterion = nn.CrossEntropyLoss().to(device)\n",
        "    else:\n",
        "      model = PreModel(hidden_dim=512).to(device)\n",
        "      #criterion = SupConLoss().to(device)\n",
        "      criterion = NT_Xent().to(device)\n",
        "\n",
        "    # Setting the optimiser\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                          lr=2e-5,\n",
        "                          betas=(0.9, 0.999),\n",
        "                          weight_decay=5e-4)\n",
        "    \n",
        "    k=4\n",
        "    th = 1 - (2*abnormal_rate)\n",
        "\n",
        "    refined_data_idx, occ, model = SSR(trainset_tuple, k, th, model, nepochs=1, verbose=1, occ_type=occ_type)\n",
        "\n",
        "    \n",
        "    if ss_type == 'rotation':\n",
        "      data_to_test = extract_features(testset_tuple, model)\n",
        "    else:\n",
        "      data_to_test = extract_features_contrastive(testset_tuple, model)\n",
        "    \n",
        "    if occ_type=='svm':\n",
        "      scores_test = -occ.score_samples(data_to_test)\n",
        "    else:\n",
        "      scores_test = score_samples(data_to_test, occ).squeeze(1).squeeze(1)\n",
        "\n",
        "    ytest = []\n",
        "    for i in range(len(testset_tuple)):\n",
        "        ytest.append(testset_tuple[i][1])\n",
        "\n",
        "    final_th = np.quantile(scores_test, th)\n",
        "    pred_test = [int(preds) for preds in scores_test > final_th]\n",
        "\n",
        "    auc_score_srr_seed.append(auc(pred_test, testset_tuple))\n",
        "\n",
        "    #NO SRR\n",
        "\n",
        "    if ss_type == 'rotation':\n",
        "      rotations_number = 4\n",
        "      model = resnet18(pretrained=False).to(device)\n",
        "      features = model.fc.in_features\n",
        "      model.fc = nn.Linear(in_features=features, out_features=rotations_number, bias=True).to(device)\n",
        "      feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "      model.feature_extractor = feature_extractor\n",
        "      criterion = nn.CrossEntropyLoss().to(device)\n",
        "    else:\n",
        "      model = PreModel(hidden_dim=512).to(device)\n",
        "      #criterion = SupConLoss().to(device)\n",
        "      criterion = NT_Xent().to(device)\n",
        "\n",
        "    # Setting the optimiser\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                          lr=3e-5,\n",
        "                          betas=(0.9, 0.999),\n",
        "                          weight_decay=5e-4)\n",
        "\n",
        "    th = 1 - (2*abnormal_rate)\n",
        "    best_loss = 10000\n",
        "    es=0\n",
        "    for epoch in range(1):\n",
        "      if ss_type == 'rotation':\n",
        "        act_loss = train(model, trainset_tuple, criterion, optimizer, epoch)\n",
        "      else:\n",
        "        act_loss = train_contrastive(model, trainset_tuple, criterion, optimizer, epoch)\n",
        "\n",
        "      es+=1\n",
        "      if act_loss < best_loss:\n",
        "        best_loss = act_loss\n",
        "        es=0\n",
        "      if es>50:\n",
        "        break\n",
        "\n",
        "    if ss_type == 'rotation':\n",
        "      data_to_train = extract_features(trainset_tuple, model)\n",
        "    else:\n",
        "      data_to_train = extract_features_contrastive(trainset_tuple, model)\n",
        "\n",
        "    if ss_type == 'rotation':\n",
        "      data_to_test = extract_features(testset_tuple, model)\n",
        "    else:\n",
        "      data_to_test = extract_features_contrastive(testset_tuple, model)\n",
        "\n",
        "    if occ_type=='svm':\n",
        "      occ = OneClassSVM(kernel='rbf', gamma=.01).fit(data_to_train)\n",
        "      scores_test = -occ.score_samples(data_to_test)\n",
        "    else:\n",
        "      occ = GaussianMixture(n_components=1, covariance_type=\"tied\", reg_covar=5e-02).fit(data_to_train)\n",
        "      scores_test = score_samples(data_to_test, occ).squeeze(1).squeeze(1)\n",
        "\n",
        "    final_th = np.quantile(scores_test, th)\n",
        "    pred_test = [int(preds) for preds in scores_test > final_th]\n",
        "    \n",
        "    auc_score_seed.append(auc(pred_test, testset_tuple))\n",
        "\n",
        "  auc_score.append(auc_score_seed)\n",
        "  auc_score_srr.append(auc_score_srr_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a590_ebNC8eA",
        "outputId": "3996fbd9-962d-4513-906e-d78f9e36ebac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------\n",
            "Epoch: 1 self-supervised contrastive loss: 0.10415507649304345\n",
            "Train evaluation\n",
            "F1: 0.05  AUC: 0.52  Average precision: 0.02\n",
            "Test evaluation\n",
            "F1: 0.08  AUC: 0.53  Average precision: 0.03\n",
            "Epoch: 1 self-supervised contrastive loss: 0.1761613738418994\n",
            "--------------------------------------------------------------------\n",
            "Epoch: 1 self-supervised contrastive loss: 0.07421724720699514\n",
            "Train evaluation\n",
            "F1: 0.02  AUC: 0.50  Average precision: 0.02\n",
            "Test evaluation\n",
            "F1: 0.04  AUC: 0.51  Average precision: 0.02\n",
            "Epoch: 1 self-supervised contrastive loss: 0.18616596756179873\n",
            "--------------------------------------------------------------------\n",
            "Epoch: 1 self-supervised contrastive loss: 0.11138941794850452\n",
            "Train evaluation\n",
            "F1: 0.16  AUC: 0.53  Average precision: 0.10\n",
            "Test evaluation\n",
            "F1: 0.20  AUC: 0.56  Average precision: 0.11\n",
            "Epoch: 1 self-supervised contrastive loss: 0.2057000065292671\n",
            "--------------------------------------------------------------------\n",
            "Epoch: 1 self-supervised contrastive loss: 0.0784280332086911\n",
            "Train evaluation\n",
            "F1: 0.14  AUC: 0.52  Average precision: 0.09\n",
            "Test evaluation\n",
            "F1: 0.19  AUC: 0.56  Average precision: 0.11\n",
            "Epoch: 1 self-supervised contrastive loss: 0.20932051873730742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avrg_auc, sd_auc = [np.mean(seed) for seed in auc_score], [np.std(seed) for seed in auc_score]\n",
        "avrg_auc_srr, sd_auc_srr = [np.mean(seed) for seed in auc_score_srr], [np.std(seed) for seed in auc_score_srr]\n",
        "ss_type_srr = 'srr + ' + ss_type\n",
        "plt.plot(abn_rates, avrg_auc_srr, '-or', color='blue', label = ss_type_srr)\n",
        "plt.fill_between(abn_rates, [avrg_auc_srr[i] - sd_auc_srr[i] for i in range(len(sd_auc_srr))], [avrg_auc_srr[i] + sd_auc_srr[i] for i in range(len(sd_auc_srr))],\n",
        "                 color='blue', alpha=0.2)\n",
        "\n",
        "plt.plot(abn_rates, avrg_auc, '-or', color='red', label = ss_type)\n",
        "plt.fill_between(abn_rates, [avrg_auc[i] - sd_auc[i] for i in range(len(sd_auc))], [avrg_auc[i] + sd_auc[i] for i in range(len(sd_auc))],\n",
        "                 color='red', alpha=0.2)\n",
        "plt.legend()\n",
        "plt.xlabel(\"Anomaly ratio in the data\")\n",
        "plt.ylabel(\"AUC\")\n",
        "title = dataset + \" dataset\"\n",
        "plt.title(title)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Ziv2DGlgshLc",
        "outputId": "0f587a67-ceb6-4da4-86bd-a28da08f7b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SRR"
      ],
      "metadata": {
        "id": "dPNz5e6XpT8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model and the loss\n",
        "ss_type = 'contrastive'\n",
        "if ss_type == 'rotation':\n",
        "  rotations_number = 4\n",
        "  model = resnet18(pretrained=False, num_classes=rotations_number).to(device)\n",
        "  feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "  model.feature_extractor = feature_extractor\n",
        "  criterion = nn.CrossEntropyLoss().to(device)\n",
        "else:\n",
        "  model = PreModel(hidden_dim=512).to(device)\n",
        "  #criterion = SupConLoss().to(device)\n",
        "  criterion = NT_Xent().to(device)"
      ],
      "metadata": {
        "id": "kSPIS6tgC9V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the optimiser\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=1e-4,\n",
        "                       betas=(0.9, 0.999),\n",
        "                       weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "-xd-Y6zqjrgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the algorithms\n",
        "k=4\n",
        "th = 1 - (2*abnormal_rate)\n",
        "\n",
        "refined_data_idx, occ, model = SSR(trainset_tuple, k, th, model, nepochs=1, verbose=0, occ_type='svm')"
      ],
      "metadata": {
        "id": "Msig8flSBT5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c21bba-39c5-49dc-df6e-d2fd1b676d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------\n",
            "Epoch: 1 self-supervised contrastive loss: 0.6157949972832792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if ss_type == 'rotation':\n",
        "  data_to_train = extract_features(trainset_tuple, model)\n",
        "else:\n",
        "  data_to_train = extract_features_contrastive(trainset_tuple, model)\n",
        "\n",
        "if ss_type == 'rotation':\n",
        "  data_to_test = extract_features(testset_tuple, model)\n",
        "else:\n",
        "  data_to_test = extract_features_contrastive(testset_tuple, model)\n",
        "\n",
        "\n",
        "\n",
        "scores_train = -occ.score_samples(data_to_train)\n",
        "scores_test = -occ.score_samples(data_to_test)\n",
        "\n",
        "\n",
        "ytrain = []\n",
        "ytest = []\n",
        "for i in range(len(trainset_tuple)):\n",
        "    ytrain.append(trainset_tuple[i][1])\n",
        "\n",
        "for i in range(len(testset_tuple)):\n",
        "    ytest.append(testset_tuple[i][1])\n",
        "\n",
        "final_th = np.quantile(scores_train, th)\n",
        "pred_train = [int(preds) for preds in scores_train > final_th]\n",
        "pred_test = [int(preds) for preds in scores_test > final_th]\n",
        "\n",
        "\n",
        "print('train')\n",
        "print(\"F1: {:.2f}  AUC: {:.2f}  Average precision: {:.2f}\".format(f1(pred_train, trainset_tuple), auc(pred_train, trainset_tuple), average_precision(pred_train, trainset_tuple)))\n",
        "print('test')\n",
        "print(\"F1: {:.2f}  AUC: {:.2f}  Average precision: {:.2f}\".format(f1(pred_test, testset_tuple), auc(pred_test, testset_tuple), average_precision(pred_test, testset_tuple)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UhqR0jl0yt2",
        "outputId": "e342627d-8a62-4c56-be3d-7a78864a0e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "F1: 0.12  AUC: 0.50  Average precision: 0.09\n",
            "test\n",
            "F1: 0.11  AUC: 0.48  Average precision: 0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training without SSR"
      ],
      "metadata": {
        "id": "K26WgwB8OxkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model and the loss\n",
        "ss_type = ''\n",
        "if ss_type == 'rotation':\n",
        "  rotations_number = 4\n",
        "  model = resnet18(pretrained=False).to(device)\n",
        "  features = model.fc.in_features\n",
        "  model.fc = nn.Linear(in_features=features, out_features=rotations_number, bias=True).to(device)\n",
        "  feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "  model.feature_extractor = feature_extractor\n",
        "  criterion = nn.CrossEntropyLoss().to(device)\n",
        "else:\n",
        "  model = PreModel(hidden_dim=512).to(device)\n",
        "  #criterion = SupConLoss().to(device)\n",
        "  criterion = NT_Xent().to(device)\n",
        "\n",
        "# Setting the optimiser\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=3e-4,\n",
        "                       betas=(0.9, 0.999),\n",
        "                       weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "yk2TfhLxFynh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "th = 1 - (2*abnormal_rate)\n",
        "best_loss = 10000\n",
        "es=0\n",
        "for epoch in range(1):\n",
        "  if ss_type == 'rotation':\n",
        "    act_loss = train(model, trainset_tuple, criterion, optimizer, epoch)\n",
        "  else:\n",
        "    act_loss = train_contrastive(model, trainset_tuple, criterion, optimizer, epoch)\n",
        "\n",
        "  es+=1\n",
        "  if act_loss < best_loss:\n",
        "    best_loss = act_loss\n",
        "    es=0\n",
        "  if es>50:\n",
        "    break\n",
        "  # occ = GaussianMixture(n_components=1, covariance_type=\"tied\", reg_covar=1e-03)\n",
        "  # if ss_type == 'rotation':\n",
        "  #   data_to_train = extract_features(trainset_tuple, model)\n",
        "  # else:\n",
        "  #   data_to_train = extract_features_contrastive(trainset_tuple, model)\n",
        "  # occ.fit(data_to_train)\n",
        "\n",
        "  # #Evaluate on train set\n",
        "  # evaluate(model, occ, trainset_tuple)\n",
        "  print('-----------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sRM7tE3O0j-",
        "outputId": "89420960-a234-4cb8-ff65-638443910a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 self-supervised contrastive loss: 0.8594699968882608\n",
            "-----------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if dataset == 'catdog':\n",
        "  testset = datasets.ImageFolder('Cat_Dog_data/test', transform=catDog_transforms)\n",
        "elif dataset == 'fmnist':\n",
        "  testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True, transform=transform)\n",
        "else:\n",
        "  testset = datasets.CIFAR10(root='data/', download=True, transform=transform)\n",
        "\n",
        "testset_tuple = preprocess_dataset(testset.data, testset.targets, len(testset.classes), abnormal_rate=abnormal_rate)"
      ],
      "metadata": {
        "id": "48OH426oj-lC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2f8c1b-c01f-4180-e00d-f4b6313d22a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if ss_type == 'rotation':\n",
        "  data_to_train = extract_features(trainset_tuple, model)\n",
        "else:\n",
        "  data_to_train = extract_features_contrastive(trainset_tuple, model)\n",
        "\n",
        "if ss_type == 'rotation':\n",
        "  data_to_test = extract_features(testset_tuple, model)\n",
        "else:\n",
        "  data_to_test = extract_features_contrastive(testset_tuple, model)\n",
        "\n"
      ],
      "metadata": {
        "id": "aLo18xx4er-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = OneClassSVM(kernel='rbf', gamma=.01).fit(data_to_train)"
      ],
      "metadata": {
        "id": "Hl1SSwGLjZFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_train = -clf.score_samples(data_to_train)\n",
        "scores_test = -clf.score_samples(data_to_test)"
      ],
      "metadata": {
        "id": "rXkRIs8rjH9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ytrain = []\n",
        "ytest = []\n",
        "for i in range(len(trainset_tuple)):\n",
        "    ytrain.append(trainset_tuple[i][1])\n",
        "\n",
        "for i in range(len(testset_tuple)):\n",
        "    ytest.append(testset_tuple[i][1])\n"
      ],
      "metadata": {
        "id": "r_DT7Yq7gnit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_th = np.quantile(scores_train, th)\n",
        "pred_train = [int(preds) for preds in scores_train > final_th]\n",
        "pred_test = [int(preds) for preds in scores_test > final_th]\n",
        "\n",
        "\n",
        "final_th"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VovU4Ys4hZn0",
        "outputId": "79bfa4e4-c460-410b-d0b4-8d2b7e74e6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-285.7750252968998"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train')\n",
        "print(\"F1: {:.2f}  AUC: {:.2f}  Average precision: {:.2f}\".format(f1(pred_train, trainset_tuple), auc(pred_train, trainset_tuple), average_precision(pred_train, trainset_tuple)))\n",
        "print('test')\n",
        "print(\"F1: {:.2f}  AUC: {:.2f}  Average precision: {:.2f}\".format(f1(pred_test, testset_tuple), auc(pred_test, testset_tuple), average_precision(pred_test, testset_tuple)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TucysI5vjnXE",
        "outputId": "77f30896-6580-4dae-9745-3bc174fe2957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "F1: 0.13  AUC: 0.50  Average precision: 0.09\n",
            "test\n",
            "F1: 0.11  AUC: 0.49  Average precision: 0.09\n"
          ]
        }
      ]
    }
  ]
}